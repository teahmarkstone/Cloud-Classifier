{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport shutil\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications.efficientnet import preprocess_input\nfrom tensorflow.python.framework.config import list_physical_devices, set_memory_growth\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-21T20:13:00.257669Z","iopub.execute_input":"2022-04-21T20:13:00.257920Z","iopub.status.idle":"2022-04-21T20:13:09.649204Z","shell.execute_reply.started":"2022-04-21T20:13:00.257894Z","shell.execute_reply":"2022-04-21T20:13:09.646066Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# set up subfolders so we have different locations to store training and test data \nos.mkdir('/kaggle/temp')\nos.chdir('/kaggle/temp')\nos.mkdir('train')\nos.mkdir('valid')\nos.mkdir('test')\nos.chdir('/kaggle/working')","metadata":{"execution":{"iopub.status.busy":"2022-04-21T20:13:37.863142Z","iopub.execute_input":"2022-04-21T20:13:37.863669Z","iopub.status.idle":"2022-04-21T20:13:37.870140Z","shell.execute_reply.started":"2022-04-21T20:13:37.863630Z","shell.execute_reply":"2022-04-21T20:13:37.869289Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# label the data path \ndata_path = '/kaggle/input/mushrooms-classification-common-genuss-images/Mushrooms'","metadata":{"execution":{"iopub.status.busy":"2022-04-21T20:11:45.924913Z","iopub.execute_input":"2022-04-21T20:11:45.925180Z","iopub.status.idle":"2022-04-21T20:11:45.929288Z","shell.execute_reply.started":"2022-04-21T20:11:45.925152Z","shell.execute_reply":"2022-04-21T20:11:45.928178Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# create a list of images and for each image, create a 2d list of pixels \nfor genus in os.listdir(data_path):\n    print('genus: ', genus)\n    # create path to current genus\n    path = f'{data_path}/{genus}'\n#     print(path)\n    # make list of each file within current genus\n    data = os.listdir(path)\n#     print('data: ', data)\n    # divvy out the images into training, valid, and testing groups\n    num_mushrooms = len(data)\n    train_mushrooms = int(num_mushrooms * .7)\n    train_path = f'/kaggle/temp/train/{genus}'\n    \n    valid_mushrooms = int(num_mushrooms * .8)\n    valid_path = f'/kaggle/temp/valid/{genus}'\n    \n    test_path = f'/kaggle/temp/test/{genus}'\n    \n    # change to the training data and create a subfolder per genus\n    os.chdir('/kaggle/temp/train')\n    os.mkdir(genus)\n    # copy over data in the training data range into the new directory \n    for mushroom in range(train_mushrooms):\n        original = f'{data_path}/{genus}/{data[mushroom]}'\n        print('original: ', original)\n        new_mushroom = f'{train_path}/{data[mushroom]}'\n        print('new: ', new_mushroom)\n        shutil.copyfile(original, new_mushroom)\n        \n    # change to the validation images and create a subfolder per genus\n    os.chdir('/kaggle/temp/valid')\n    os.mkdir(genus)\n    # copy over data in the validation data range into the new directory\n    for mushroom in range(train_mushrooms, valid_mushrooms):\n        original = f'{data_path}/{genus}/{data[mushroom]}'\n        new_mushroom = f'{valid_path}/{data[mushroom]}'\n        shutil.copyfile(original, new_mushroom)\n    \n    # change the to testing data\n    os.chdir('/kaggle/temp/test')\n    os.mkdir(genus)\n    # copy over data from the testing images and put images in a new dir\n    for mushroom in range(valid_mushrooms, num_mushrooms):\n        original = f'{data_path}/{genus}/{data[mushroom]}'\n        new_mushroom = f'{test_path}/{data[mushroom]}'\n        shutil.copyfile(original, new_mushroom)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T20:14:01.431703Z","iopub.execute_input":"2022-04-21T20:14:01.431957Z","iopub.status.idle":"2022-04-21T20:14:29.983011Z","shell.execute_reply.started":"2022-04-21T20:14:01.431925Z","shell.execute_reply":"2022-04-21T20:14:29.982295Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# from PIL import ImageFile\n# ImageFile.LOAD_TRUNCATED_IMAGES = True\n\n# import matplotlib.pyplot as plt\n# import matplotlib.image as mpimg\n# %matplotlib inline\n\n# # Settings for displaying charts\n# plt.rcParams['figure.figsize'] = 12, 8\n# plt.rcParams.update({'font.size': 12})\n\nphysical_devices = list_physical_devices('GPU')\nprint(f'Number of GPUs available: {len(physical_devices)}')\n\nif len(physical_devices) > 0:\n    set_memory_growth(physical_devices[0], True)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T20:15:04.906434Z","iopub.execute_input":"2022-04-21T20:15:04.906679Z","iopub.status.idle":"2022-04-21T20:15:04.913941Z","shell.execute_reply.started":"2022-04-21T20:15:04.906652Z","shell.execute_reply":"2022-04-21T20:15:04.912320Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications.efficientnet import preprocess_input","metadata":{"execution":{"iopub.status.busy":"2022-04-21T20:16:05.558513Z","iopub.execute_input":"2022-04-21T20:16:05.558765Z","iopub.status.idle":"2022-04-21T20:16:05.564445Z","shell.execute_reply.started":"2022-04-21T20:16:05.558735Z","shell.execute_reply":"2022-04-21T20:16:05.563756Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# standardize the batch and image size\nimage_dim = 320\nbatch_size = 32","metadata":{"execution":{"iopub.status.busy":"2022-04-21T20:16:08.296727Z","iopub.execute_input":"2022-04-21T20:16:08.297250Z","iopub.status.idle":"2022-04-21T20:16:08.300812Z","shell.execute_reply.started":"2022-04-21T20:16:08.297212Z","shell.execute_reply":"2022-04-21T20:16:08.300029Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# training data image set \ntraining_images = ImageDataGenerator(preprocessing_function=preprocess_input, horizontal_flip=True,\n                                         width_shift_range=0.1, height_shift_range=0.1)\\\n                    .flow_from_directory(directory='/kaggle/temp/train',\n                                         target_size=(image_dim, image_dim),\n                                         class_mode= 'categorical',\n                                         batch_size= batch_size,\n                                         shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T20:16:08.926432Z","iopub.execute_input":"2022-04-21T20:16:08.926678Z","iopub.status.idle":"2022-04-21T20:16:09.145969Z","shell.execute_reply.started":"2022-04-21T20:16:08.926651Z","shell.execute_reply":"2022-04-21T20:16:09.145258Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# validation data image set \nvalid_images = ImageDataGenerator(preprocessing_function=preprocess_input)\\\n                    .flow_from_directory(directory='/kaggle/temp/valid',\n                                         target_size=(image_dim, image_dim),\n                                         class_mode= 'categorical',\n                                         batch_size= batch_size,\n                                         shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T20:16:09.294346Z","iopub.execute_input":"2022-04-21T20:16:09.294733Z","iopub.status.idle":"2022-04-21T20:16:09.405604Z","shell.execute_reply.started":"2022-04-21T20:16:09.294702Z","shell.execute_reply":"2022-04-21T20:16:09.404909Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# test data image set \ntest_images = ImageDataGenerator(preprocessing_function=preprocess_input)\\\n                    .flow_from_directory(directory='/kaggle/temp/test',\n                                         target_size=(image_dim, image_dim),\n                                         class_mode='categorical',\n                                         batch_size=batch_size,\n                                         shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T20:16:09.679363Z","iopub.execute_input":"2022-04-21T20:16:09.679614Z","iopub.status.idle":"2022-04-21T20:16:09.789451Z","shell.execute_reply.started":"2022-04-21T20:16:09.679587Z","shell.execute_reply":"2022-04-21T20:16:09.788787Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# from tensorflow.keras.models import Sequential\n# from tensorflow.keras.layers import Dense, Embedding, Flatten\n# from tensorflow.keras.optimizers import SGD\n# from tensorflow.keras.initializers import HeNormal","metadata":{"execution":{"iopub.status.busy":"2022-04-21T20:16:10.132572Z","iopub.execute_input":"2022-04-21T20:16:10.132821Z","iopub.status.idle":"2022-04-21T20:16:10.138644Z","shell.execute_reply.started":"2022-04-21T20:16:10.132794Z","shell.execute_reply":"2022-04-21T20:16:10.137750Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \nimport tensorflow as tf\nmodel = tf.keras.applications.efficientnet.EfficientNetB7(\n    include_top=False,\n    weights='imagenet',\n    input_tensor=None,\n    input_shape=(image_dim, image_dim, 3),\n    pooling='avg',\n    classes=1000,\n    classifier_activation='softmax'\n)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T20:20:29.848856Z","iopub.execute_input":"2022-04-21T20:20:29.849132Z","iopub.status.idle":"2022-04-21T20:20:35.955143Z","shell.execute_reply.started":"2022-04-21T20:20:29.849096Z","shell.execute_reply":"2022-04-21T20:20:35.954425Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# wrap model and add last dense layer\nnew_model = tf.keras.models.Sequential(\n    [\n        model,\n        tf.keras.layers.Dense(9, activation='softmax')\n    ]\n)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T20:22:39.498582Z","iopub.execute_input":"2022-04-21T20:22:39.499212Z","iopub.status.idle":"2022-04-21T20:22:41.735790Z","shell.execute_reply.started":"2022-04-21T20:22:39.499174Z","shell.execute_reply":"2022-04-21T20:22:41.735088Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"new_model.layers[0].trainable = False\n# Metrics and optimizer\nnew_model.compile(loss='categorical_crossentropy',\n                  optimizer='adam',\n                  metrics=['accuracy'])\n","metadata":{"execution":{"iopub.status.busy":"2022-04-21T20:23:51.694168Z","iopub.execute_input":"2022-04-21T20:23:51.694872Z","iopub.status.idle":"2022-04-21T20:23:51.740664Z","shell.execute_reply.started":"2022-04-21T20:23:51.694839Z","shell.execute_reply":"2022-04-21T20:23:51.740016Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"new_model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T20:23:52.537957Z","iopub.execute_input":"2022-04-21T20:23:52.538266Z","iopub.status.idle":"2022-04-21T20:23:52.609483Z","shell.execute_reply.started":"2022-04-21T20:23:52.538235Z","shell.execute_reply":"2022-04-21T20:23:52.607147Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# Callbacks \nearly_stop = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy',\n                                              patience=10,\n                                              restore_best_weights=True)\n\nreduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy',\n                                                 factor=0.1,\n                                                 mode='max',\n                                                 cooldown=2,\n                                                 patience=2,\n                                                 min_lr=0)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T20:23:54.530027Z","iopub.execute_input":"2022-04-21T20:23:54.530607Z","iopub.status.idle":"2022-04-21T20:23:54.535643Z","shell.execute_reply.started":"2022-04-21T20:23:54.530571Z","shell.execute_reply":"2022-04-21T20:23:54.534622Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# Train new model:\nnetwork_history = new_model.fit(training_images,\n                        validation_data=valid_images,\n                        epochs=10,\n                        steps_per_epoch=79,\n                        validation_steps=16,\n                        verbose=2,\n                        callbacks=[reduce_lr, early_stop],\n                        use_multiprocessing=True,\n                        workers=2)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T20:26:38.438559Z","iopub.execute_input":"2022-04-21T20:26:38.439453Z","iopub.status.idle":"2022-04-21T20:43:33.012462Z","shell.execute_reply.started":"2022-04-21T20:26:38.439367Z","shell.execute_reply":"2022-04-21T20:43:33.008028Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"loss, accuracy = new_model.evaluate(test_images,\n                                    steps=11, \n                                    verbose=2, \n                                    use_multiprocessing=True, \n                                    workers=2)\nprint(f'Model performance on test images:\\nAccuracy = {accuracy}\\nLoss = {loss}')","metadata":{"execution":{"iopub.status.busy":"2022-04-21T20:43:52.794193Z","iopub.execute_input":"2022-04-21T20:43:52.794658Z","iopub.status.idle":"2022-04-21T20:44:00.833630Z","shell.execute_reply.started":"2022-04-21T20:43:52.794622Z","shell.execute_reply":"2022-04-21T20:44:00.832662Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}